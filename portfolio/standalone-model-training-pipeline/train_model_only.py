# -*- coding: utf-8 -*-
"""Train-model-only.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j1Y24hFYl8t0ecVGY7cAyB7j62Y3fSmu

# Restart the session after running this cell
"""

# Restart the session after running this cell
!pip install -q "numpy<2"

!pip install -q scikit-surprise

"""# Data Preprocessing"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from surprise import SVD, Dataset, Reader, accuracy
from surprise.model_selection import GridSearchCV, train_test_split

# Load the dataset and rename columns as provided
new_columns = [
    "userid", "churches", "resorts", "beaches", "parks", "theatres", "museums",
    "malls", "zoos", "restaurants", "pubs/bars", "local services", "burger/pizza shops",
    "hotels/other lodgings", "juice bars", "art galleries", "dance clubs",
    "swimming pools", "gyms", "bakeries", "beauty & spas", "cafes",
    "view points", "monuments", "gardens"
]

file_path = "google_review_ratings.csv"  # Make sure this file is in your Colab workspace
df = pd.read_csv(file_path)
df.drop(columns=['Unnamed: 25'], errors='ignore', inplace=True)
df.columns = new_columns

# Convert all rating columns to numeric and fill missing values with column mean
for col in new_columns[1:]:
    df[col] = pd.to_numeric(df[col], errors='coerce')
    df[col] = df[col].fillna(df[col].mean())

# Display a quick preview of the data
df.head()

# Transform the dataframe from wide to long format: (userid, category, rating)
df_long = pd.melt(df, id_vars=['userid'], var_name='category', value_name='rating')

# Preview the transformed data
df_long.head()

"""# Train the Collaborative filtering (CF) model"""

# Prepare data for the Surprise library
reader = Reader(rating_scale=(df_long['rating'].min(), df_long['rating'].max()))
data = Dataset.load_from_df(df_long[['userid', 'category', 'rating']], reader)

# Define a parameter grid for tuning SVD hyperparameters
param_grid = {
    'n_factors': [15, 20, 25],
    'lr_all': [0.002, 0.005, 0.01],
    'reg_all': [0.02, 0.05, 0.1]
}

# Use GridSearchCV to find the best hyperparameters based on RMSE
gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)
gs.fit(data)
best_params = gs.best_params['rmse']
print("Best Hyperparameters based on RMSE:", best_params)

# Split data into training and testing sets
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Train SVD model with the best parameters
model = SVD(n_factors=best_params['n_factors'],
            lr_all=best_params['lr_all'],
            reg_all=best_params['reg_all'],
            random_state=42)
model.fit(trainset)

# Evaluate model performance on the test set
predictions = model.test(testset)
print("RMSE on test set: ", accuracy.rmse(predictions))

"""# Test the Trained Model"""

import pickle
from tabulate import tabulate

# Function to generate predicted ratings for a given user for all categories
def get_prediction(user, category):
    return model.predict(user, category).est

categories = new_columns[1:]

def get_user_predictions(user):
    """ Create a dictionary with predicted ratings for each category. """
    return {cat: get_prediction(user, cat) for cat in categories}

# Provide available user IDs for input validation (sorting by the numeric part)
available_users = sorted(df['userid'].unique(), key=lambda x: int(x.split()[1]))
print("\nAvailable user IDs:", available_users)
print("User ID range: from {} to {}".format(available_users[0], available_users[-1]))

# Interactive input to get recommendations for a specific user
user_input = input("\nEnter a user number (e.g., '1' for User 1): ").strip()

# If the user input is a digit, convert it to the full user ID format
if user_input.isdigit():
    input_user = "User " + user_input
else:
    input_user = user_input  # assume user already provided in correct format

# Validate the input and print predictions if valid
if input_user not in available_users:
    print("Invalid user ID. Please choose a number corresponding to one of the available IDs:")
    print("Available user numbers:", [u.split()[1] for u in available_users])
else:
    # Get predictions for the specified user
    user_predictions = get_user_predictions(input_user)

    # Sort predictions in descending order (highest rating first)
    sorted_predictions = sorted(user_predictions.items(), key=lambda x: x[1], reverse=True)

    # Prepare data for the tabulated output
    table_data = []
    for category, rating in sorted_predictions:
        stars = "★" * int(round(rating))
        table_data.append([category, f"{rating:.2f}", stars])

    # Print tabulated predictions
    print(f"\nOverall Predicted Ratings for {input_user} (Sorted High to Low):\n")
    print(tabulate(table_data, headers=["Category", "Rating", "Stars"], tablefmt="fancy_grid", maxcolwidths=[None, None, 6]))

"""# Save the model"""

import pickle

# Define the filename to save the model
model_filename = "trained_model.pkl"

# Save the trained model to disk
with open(model_filename, "wb") as file:
    pickle.dump(model, file)

print(f"Trained model saved to {model_filename}")

"""# Load a saved Model and use it

Once this model is saved you dont have to train the model again just run the below cell and adjust the path to your saved model and directly start using the saved model for predictions without wasting time on the training again
"""

import pickle
from tabulate import tabulate

# Load the trained model
model_filename = "trained_model.pkl"
with open(model_filename, "rb") as file:
    loaded_model = pickle.load(file)

print(f"Model loaded successfully from {model_filename}")

# Function to get predictions
def get_loaded_model_prediction(user, category):
    return loaded_model.predict(user, category).est

# Get user input
user_input = input("\nEnter a user number (e.g., '1' for User 1): ").strip()
input_user = f"User {user_input}" if user_input.isdigit() else user_input

if input_user not in available_users:
    print("Invalid user ID. Please choose a valid user.")
else:
    user_predictions = {
        cat: get_loaded_model_prediction(input_user, cat) for cat in categories
    }

    # Sort predictions in descending order
    sorted_predictions = sorted(user_predictions.items(), key=lambda x: x[1], reverse=True)

    # Prepare data for tabulation
    table_data = []
    for category, rating in sorted_predictions:
        stars = "★" * int(round(rating))
        table_data.append([category, f"{rating:.2f}", stars])

    # Print table with the Stars column fixed to a max width of 6 characters.
    print(f"\nPredicted Ratings for {input_user} (Sorted High to Low):\n")
    print(tabulate(table_data,
                   headers=["Category", "Rating", "Stars"],
                   tablefmt="fancy_grid",
                   maxcolwidths=[None, None, 6]))

