
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Acquisition\n",
    "df = pd.read_csv('your_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204dcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Step 2: Text Cleaning\n",
    "# Removing duplicates\n",
    "df = df.drop_duplicates(subset=['title', 'body'])\n",
    "# Removing null entries\n",
    "df = df.dropna(subset=['title', 'body'])\n",
    "# Removing stop words, punctuation, and special characters\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['cleaned_title'] = df['title'].apply(lambda x: ' '.join([word for word in word_tokenize(str(x)) if word.lower() not in stop_words and word.isalnum()]))\n",
    "df['cleaned_body'] = df['body'].apply(lambda x: ' '.join([word for word in word_tokenize(str(x)) if word.lower() not in stop_words and word.isalnum()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac59780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Step 3: Preprocessing\n",
    "# Tokenization\n",
    "df['tokenized_title'] = df['cleaned_title'].apply(lambda x: word_tokenize(x))\n",
    "df['tokenized_body'] = df['cleaned_body'].apply(lambda x: word_tokenize(x))\n",
    "# Stemming\n",
    "ps = PorterStemmer()\n",
    "df['stemmed_title'] = df['tokenized_title'].apply(lambda x: [ps.stem(word) for word in x])\n",
    "df['stemmed_body'] = df['tokenized_body'].apply(lambda x: [ps.stem(word) for word in x])\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_title'] = df['tokenized_title'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "df['lemmatized_body'] = df['tokenized_body'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Mapping ratings to sentiments (1-2: Negative, 3: Neutral, 4-5: Positive)\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 'negative' if x in [1, 2] else 'neutral' if x == 3 else 'positive')\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "df['sentiment_encoded'] = le.fit_transform(df['sentiment'])\n",
    "# Concatenating title and body into a single text field\n",
    "df['text'] = df['cleaned_title'] + ' ' + df['cleaned_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Step 4: Exploratory Data Analysis (EDA)\n",
    "# Distribution of Ratings\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='rating', data=df)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Distribution\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# Word Cloud for Title\n",
    "title_text = ' '.join(df['cleaned_title'].dropna())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(title_text)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Title')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Body\n",
    "body_text = ' '.join(df['cleaned_body'].dropna())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(body_text)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Body')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4891062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Top 10 Most Common Words in Title\n",
    "title_words = ' '.join(df['cleaned_title'].dropna()).split()\n",
    "title_word_counts = Counter(title_words)\n",
    "top_10_title_words = title_word_counts.most_common(10)\n",
    "top_10_title_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f06356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Most Common Words in Body\n",
    "body_words = ' '.join(df['cleaned_body'].dropna()).split()\n",
    "body_word_counts = Counter(body_words)\n",
    "top_10_body_words = body_word_counts.most_common(10)\n",
    "top_10_body_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Helpful Votes\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df['helpfulVotes'], kde=True)\n",
    "plt.title('Distribution of Helpful Votes')\n",
    "plt.xlabel('Helpful Votes')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Text Lengths\n",
    "df['text_length'] = df['text'].apply(len)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
